# PTX Loader

## Overview

The PTX Loader handles loading, parsing, and caching CUDA kernels from PTX files. It works with accompanying JSON files that provide human-readable metadata.

```
Build-Time (Triton/Python)          Runtime (C#)
                                    
    Triton Kernel (.py)             ┌──────────────┐
           │                        │  PTX Loader  │
           ▼                        │              │
    triton.compile()                │  - Parse     │
           │                        │  - Validate  │
           ▼                        │  - Cache     │
    ┌──────────────────┐           │              │
    │ kernel_name.ptx  │──────────▶│              │
    │ kernel_name.json │──────────▶│              │
    └──────────────────┘           └──────┬───────┘
                                          │
                                          ▼
                                   CUmodule (loaded)
                                   KernelDescriptor
```

---

## Triton to PTX Workflow

### Writing Triton Kernels

```python
# kernels/vector_add.py
import triton
import triton.language as tl

@triton.jit
def vector_add_kernel(
    a_ptr,      # Pointer to first input
    b_ptr,      # Pointer to second input
    c_ptr,      # Pointer to output
    n_elements, # Number of elements
    BLOCK_SIZE: tl.constexpr,  # Block size (compile-time)
):
    pid = tl.program_id(0)
    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)
    mask = offsets < n_elements
    
    a = tl.load(a_ptr + offsets, mask=mask)
    b = tl.load(b_ptr + offsets, mask=mask)
    c = a + b
    
    tl.store(c_ptr + offsets, c, mask=mask)
```

### Compiling to PTX

```python
# build_kernels.py
from triton.compiler import compile

def compile_kernel(kernel_fn, signature, output_path):
    compiled = compile(
        kernel_fn,
        signature=signature,
        # Target compute capability
        cc=(8, 0),  # SM 8.0 (Ampere)
    )
    
    # Extract PTX
    ptx_code = compiled.asm['ptx']
    
    # Save PTX
    with open(output_path, 'w') as f:
        f.write(ptx_code)
    
    return compiled

# Example usage
compiled = compile_kernel(
    vector_add_kernel,
    signature="*fp32, *fp32, *fp32, i32",
    output_path="kernels/vector_add.ptx"
)
```

### Generating JSON Metadata

Alongside each PTX file, generate a JSON file with metadata:

```python
# generate_metadata.py
import json

def generate_metadata(compiled, kernel_name, output_path):
    metadata = {
        "name": kernel_name,
        "version": "1.0",
        "category": "math",
        "summary": "Element-wise vector addition",
        "tags": ["vector", "addition", "elementwise"],
        
        "parameters": [
            {
                "index": 0,
                "name": "A",
                "ptx_type": ".u64",
                "is_pointer": True,
                "element_type": "f32",
                "direction": "in",
                "semantic": "input_buffer"
            },
            {
                "index": 1,
                "name": "B",
                "ptx_type": ".u64",
                "is_pointer": True,
                "element_type": "f32",
                "direction": "in",
                "semantic": "input_buffer"
            },
            {
                "index": 2,
                "name": "C",
                "ptx_type": ".u64",
                "is_pointer": True,
                "element_type": "f32",
                "direction": "out",
                "semantic": "output_buffer",
                "shape_rule": "same(0)"
            },
            {
                "index": 3,
                "name": "Count",
                "ptx_type": ".u32",
                "is_pointer": False,
                "direction": "in",
                "semantic": "element_count"
            }
        ],
        
        "max_threads": [1024, 1, 1],
        "shared_memory_static": 0,
        
        "generated": True,
        "needs_review": True,
        "ptx_version": "8.0",
        "target_sm": "sm_80"
    }
    
    with open(output_path, 'w') as f:
        json.dump(metadata, f, indent=2)

# Usage
generate_metadata(compiled, "vector_add_f32", "kernels/vector_add.json")
```

---

## PTX File Format

The PTX file contains the compiled kernel code:

```ptx
//
// Generated by Triton
//
.version 8.0
.target sm_80
.address_size 64

.visible .entry vector_add_f32(
    .param .u64 param_0,    // a_ptr
    .param .u64 param_1,    // b_ptr
    .param .u64 param_2,    // c_ptr
    .param .u32 param_3     // n_elements
)
.maxntid 256, 1, 1
{
    .reg .pred  %p<3>;
    .reg .f32   %f<4>;
    .reg .b32   %r<8>;
    .reg .b64   %rd<10>;
    
    // Kernel body...
    ld.param.u64    %rd1, [param_0];
    ld.param.u64    %rd2, [param_1];
    ld.param.u64    %rd3, [param_2];
    ld.param.u32    %r1,  [param_3];
    
    // ...compute...
    
    ret;
}
```

---

## JSON Metadata Format

```json
{
  "name": "vector_add_f32",
  "version": "1.0",
  "category": "math",
  "summary": "Element-wise addition of two float32 vectors",
  "tags": ["vector", "addition", "elementwise"],
  
  "parameters": [
    {
      "index": 0,
      "name": "A",
      "ptx_type": ".u64",
      "is_pointer": true,
      "alignment": 16,
      "element_type": "f32",
      "direction": "in",
      "semantic": "input_buffer",
      "shape_rule": null
    },
    {
      "index": 1,
      "name": "B",
      "ptx_type": ".u64",
      "is_pointer": true,
      "alignment": 16,
      "element_type": "f32",
      "direction": "in",
      "semantic": "input_buffer",
      "shape_rule": null
    },
    {
      "index": 2,
      "name": "C",
      "ptx_type": ".u64",
      "is_pointer": true,
      "alignment": 16,
      "element_type": "f32",
      "direction": "out",
      "semantic": "output_buffer",
      "shape_rule": "same(0)"
    },
    {
      "index": 3,
      "name": "Count",
      "ptx_type": ".u32",
      "is_pointer": false,
      "direction": "in",
      "semantic": "element_count"
    }
  ],
  
  "max_threads": [256, 1, 1],
  "req_threads": null,
  "shared_memory_static": 0,
  "uses_dynamic_shared": false,
  
  "generated": true,
  "needs_review": true,
  "ptx_version": "8.0",
  "target_sm": "sm_80"
}
```

### Parameter Fields

| Field | Description |
|-------|-------------|
| `index` | Parameter position in kernel signature |
| `name` | Human-readable name |
| `ptx_type` | PTX type (`.u64`, `.f32`, etc.) |
| `is_pointer` | True if this is a buffer pointer |
| `alignment` | Required memory alignment |
| `element_type` | Element type if pointer (f32, u8, etc.) |
| `direction` | `in`, `out`, `inout`, or `unknown` |
| `semantic` | Hint: `input_buffer`, `output_buffer`, `element_count`, etc. |
| `shape_rule` | Rule for inferring output shape |

### Shape Rules

```
"same"           → Output has same shape as first input
"same(N)"        → Output has same shape as input N
"broadcast(0,1)" → Output is broadcast of inputs 0 and 1
"[N, 16]"        → Output is [input0.dim0, 16]
"scalar"         → Output is a single element
```

---

## PTX Parsing (Runtime)

The PTX Loader parses PTX to extract:
1. Entry points (`.visible .entry`)
2. Parameter types (`.param`)
3. Performance hints (`.maxntid`, `.maxnreg`)
4. Shared memory requirements

### Parsing Entry Points

```csharp
public class PTXParser
{
    private static readonly Regex EntryRegex = new(
        @"\.visible\s+\.entry\s+(\w+)\s*\(([^)]*)\)",
        RegexOptions.Compiled);
    
    private static readonly Regex ParamRegex = new(
        @"\.param\s+(\.u64|\.u32|\.f32|\.f64)\s+(\w+)",
        RegexOptions.Compiled);
    
    public List<KernelInfo> Parse(string ptxSource)
    {
        var kernels = new List<KernelInfo>();
        
        foreach (Match match in EntryRegex.Matches(ptxSource))
        {
            var name = match.Groups[1].Value;
            var paramBlock = match.Groups[2].Value;
            
            var parameters = ParseParameters(paramBlock);
            var hints = ExtractPerformanceHints(ptxSource, name);
            
            kernels.Add(new KernelInfo
            {
                EntryPoint = name,
                Parameters = parameters,
                MaxThreads = hints.MaxThreads,
                SharedMemory = hints.SharedMemory
            });
        }
        
        return kernels;
    }
}
```

### Dataflow Analysis for Direction

When JSON doesn't specify direction, analyze PTX:

```csharp
public ParamDirection InferDirection(string ptxSource, int paramIndex)
{
    // Look for load/store patterns on this parameter
    var paramReg = $"param_{paramIndex}";
    
    bool hasLoad = Regex.IsMatch(ptxSource, $@"ld\.param\.u64\s+%\w+,\s+\[{paramReg}\]");
    bool hasStore = Regex.IsMatch(ptxSource, $@"st\.global\.\w+\s+\[%rd\d+");
    
    // This is simplified - real analysis traces register usage
    if (hasLoad && !hasStore) return ParamDirection.In;
    if (hasStore && !hasLoad) return ParamDirection.Out;
    if (hasLoad && hasStore) return ParamDirection.InOut;
    return ParamDirection.Unknown;
}
```

---

## Module Cache

Compiled CUDA modules are cached to avoid recompilation:

```csharp
public class ModuleCache
{
    private readonly ConcurrentDictionary<string, CachedModule> _cache = new();
    
    public CudaModule Get(string ptxPath, CudaContext context)
    {
        var key = $"{ptxPath}:{context.DeviceId}";
        
        return _cache.GetOrAdd(key, _ =>
        {
            var ptxSource = File.ReadAllText(ptxPath);
            var module = context.LoadModulePTX(ptxSource);
            
            return new CachedModule
            {
                Module = module,
                LoadTime = DateTime.UtcNow,
                FileHash = ComputeHash(ptxSource)
            };
        }).Module;
    }
    
    public void Invalidate(string ptxPath)
    {
        var keysToRemove = _cache.Keys
            .Where(k => k.StartsWith(ptxPath))
            .ToList();
        
        foreach (var key in keysToRemove)
        {
            if (_cache.TryRemove(key, out var cached))
                cached.Module.Dispose();
        }
    }
}
```

---

## File Sync Pattern (VL.Stride Inspired)

VL.Stride loads shaders using a file-sync pattern. VL.Cuda follows similar principles:

### VL.Stride Pattern

```
Shader.sdsl           ← Source file
Shader.sdsl.meta      ← Generated metadata
Shader.bytecode       ← Compiled code

FileWatcher detects changes → Recompile → Hot-reload
```

### VL.Cuda Pattern

```
kernel.ptx            ← Compiled PTX (from Triton build)
kernel.json           ← Metadata (generated or hand-edited)

FileWatcher detects changes:
  - kernel.ptx changed → Invalidate cache, rebuild graph
  - kernel.json changed → Reload metadata only
```

### Implementation

```csharp
public class KernelFileWatcher : IDisposable
{
    private FileSystemWatcher _watcher;
    private ModuleCache _cache;
    
    public event Action<string> OnKernelChanged;
    
    public KernelFileWatcher(string kernelDirectory, ModuleCache cache)
    {
        _cache = cache;
        _watcher = new FileSystemWatcher(kernelDirectory)
        {
            Filter = "*.ptx",
            NotifyFilter = NotifyFilters.LastWrite | NotifyFilters.FileName
        };
        
        _watcher.Changed += OnFileChanged;
        _watcher.Created += OnFileChanged;
        _watcher.EnableRaisingEvents = true;
    }
    
    private void OnFileChanged(object sender, FileSystemEventArgs e)
    {
        // Debounce (file might be written in chunks)
        Thread.Sleep(100);
        
        _cache.Invalidate(e.FullPath);
        OnKernelChanged?.Invoke(e.FullPath);
    }
}
```

---

## Loading Flow

```csharp
public KernelDescriptor LoadKernel(string ptxPath)
{
    // 1. Check for JSON metadata
    var jsonPath = Path.ChangeExtension(ptxPath, ".json");
    
    if (File.Exists(jsonPath))
    {
        // Load from JSON
        var json = File.ReadAllText(jsonPath);
        return JsonSerializer.Deserialize<KernelDescriptor>(json);
    }
    
    // 2. Parse PTX for basic info
    var ptxSource = File.ReadAllText(ptxPath);
    var parsed = PTXParser.Parse(ptxSource);
    
    // 3. Generate descriptor
    var descriptor = new KernelDescriptor
    {
        PTXPath = ptxPath,
        EntryPoint = parsed.EntryPoint,
        Parameters = parsed.Parameters.Select(p => new KernelParamDescriptor
        {
            Index = p.Index,
            PtxType = p.Type,
            IsPointer = p.IsPointer,
            Direction = ParamDirection.Unknown,  // Can't infer without JSON
            Name = $"param_{p.Index}"
        }).ToList(),
        Generated = true,
        NeedsReview = true
    };
    
    // 4. Optionally write JSON for user to edit
    if (GenerateJsonOnLoad)
    {
        var json = JsonSerializer.Serialize(descriptor, new JsonSerializerOptions { WriteIndented = true });
        File.WriteAllText(jsonPath, json);
    }
    
    return descriptor;
}
```

---

## Error Handling

```csharp
public class KernelLoadException : Exception
{
    public string PTXPath { get; }
    public string? JsonPath { get; }
    public KernelLoadError Error { get; }
}

public enum KernelLoadError
{
    PTXFileNotFound,
    PTXParseError,
    JSONParseError,
    EntryPointNotFound,
    ParameterMismatch,
    UnsupportedPTXVersion
}
```

---

## Best Practices

1. **Always provide JSON**: Auto-generated JSON is a starting point, human-edited is better
2. **Version your kernels**: Include version in metadata
3. **Use meaningful names**: `particle_emit_sphere` not `kernel_001`
4. **Document parameters**: Fill in descriptions
5. **Test compatibility**: Different SM versions may need different PTX
6. **Cache aggressively**: PTX JIT compilation is expensive
7. **Watch for changes**: Support hot-reload during development
